\documentclass[a4paper,12pt]{article}
\usepackage[utf8x]{inputenc}
\usepackage[numbers,sort&compress]{natbib}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{fullpage}

\title{IRP proposal}
\author{Pengfei Gao, s1144374}

\begin{document}

\maketitle

\begin{abstract}

In the recent days, the social networking media has been widely used by more and more people. There is a growing need to develop a powerful and efficient system tools to mining the useful and important information from the huge amount of data generated by users from those social networking media. The aim of this project is to develop such a real-time First Story Detection system to detect current hot events from the real-time stream of Twitter. The project will use Apache Distributed Stream Computing platform(S4) to process continuous unbounded streams of data and locality-sensitive hashing method to extract the features from the tweets.

\end{abstract}



\section{Purpose}

-a statement of the problem to be addressed. This should include arguments as to why solving the problem is important; e.g., because it will enable certain applications, or lead to interesting scientific discoveries.


Twitter is a popular real-time information network that users can present and find the latest ideas, stories, news and opinions on what they interested. For example, when the news the pop star Michael Jackson's death came out, 22.64\% of the tweets posted contains the phrase "Michael Jackson", which enables the detection of the current hot events promptly. 


New event detection includes topic detection and tracking. 








\section{Background}

-a short description of how previous work addresses (or fails to address) this problem, leading to a rationale for the hypotheses that you intend to test, and a convincing argument about how that hypotheses might solve the problem.





\section{Methods}

-A description of the methods and techniques you intend to use to test your hypotheses (e.g., data analysis procedures, experimental design etc), indicating that alternatives have been considered and ruled out on sound scientific grounds.

"First Story Detection" deals with spotting breaking news. For example, as soon as an earthquake happens, we want to know about it. We do not care about follow-up stories. Now, Twitter can be an excellent source of first stories and we have shown how they can be spotted using scalable algorithms based upon locality sensitive hashing. However, our system only works on a single processor and is not real-time.

S4 (the "real time hadoop" by Yahoo) is a distributed processing system which spreads computation over a network of machines. Tasks communicate with each other via remote procedure calls (there is no use of disks) using key-value pairs. Because of this, processing is scalable and fast. S4 is written in java.

This project will look at how S4 can be used for First Story Detection in Twitter. Tweets will be provided. The focus here will be on investigating how to design such a system, looking at questions such as throughput rate, robustness and scaling and how.


Locality-sensitive hashing


ZooKeeper is a distributed, open-source coordination service which allows distributed processes to coordinate with each other through a shared hierarchal namespace which is organized similarly to a standard file system.  
ZooKeeper data is kept in-memory, which means ZooKeeper can achieve high throughput and low latency numbers.


S4 is a general-purpose, distributed, scalable, pluggable platform that used for processing continuous unbounded streams of data. 



In S4, Events are arbitrary Java Objects that can be passed between PEs. Adapters convert the external incoming data streams into Events and then dispatched in named streams which identified by a key stream name.

Keyed data events are routed with affinity to Processing Elements (PEs), which consume the events and emit one or more events which may be consumed by other PEs, or publish results, possibly to an external data store or consumer.

Processing Nodes (PNs) are the logical host to PEs which are responsible for listening to events, executing operations on the incoming events, dispatching events with the help of the communication layer, and emitting output events. 

Key-less PEs usually serve as entry point PEs: That is, the PEs that receive events from the outside world. This is because an adapter typically does not choose an S4 node based on a key in the event, but randomly (or in some other fashion that evenly distributes the events amongst the S4 nodes).

We will define a PE type called TweetReceiverPE which is configured to listen to the tweets stream. 



-------------

In the context of first story detection, we can not store all the tweets in the memory nor compare the new tweets to all the existed tweets. Therefore, for an unbounded tweets streaming, the streaming FSD system should detect the tweet's topic and then make decisions whether the topic is seen before or a new one and then process the next tweet. 






\section{Evaluation}

-Details of the metrics by which you will evaluate the outcomes of your research; e.g., by comparing the output of your system with some gold standard, or with the ways in which humans perform a task, etc.


Implemented a system based on S4 to spot breaking news in Twitter.




\section{Outpus}

- A description of what the outputs of the projects will be: e.g., these might include an extension or change to some existing theory or to some piece of software, some new data (e.g., annotated linguistic data), and so on.





\section{Workplan}

-A timetable or research plan, detailing what will be done to complete the proposed project, and when these tasks will be completed by.







\bibliographystyle{plain}
\bibliography{refs}


\end{document}
